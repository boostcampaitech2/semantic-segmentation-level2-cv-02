# Boostcamp Recycle Trash Semantic Segmentation Challenge
Code for 20th place solution in Boostcamp AI Tech Recycle Trash Semantic Segmentation Challenge.

## ğŸ“‹ Table of content

- [íŒ€ ì†Œê°œ](#Team)<br>
- [ëŒ€íšŒ ê°œìš”](#Overview)<br>
- [ë¬¸ì œ ì •ì˜ í•´ê²° ë° ë°©ë²•](#Solution)<br>
- [CODE ì„¤ëª…](#Code)<br>
- [Demo ê²°ê³¼](#Demo)

<br></br>
## ğŸ‘‹ íŒ€ ì†Œê°œ <a name = 'Team'></a>
Contributors  

|ê¹€ì„œì›|ì´ìœ ì§„|ì´í•œë¹ˆ|ì •ì„¸ì¢…|ì¡°í˜„ë™|í—ˆì§€í›ˆ|í—ˆì •í›ˆ|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|<a href='https://github.com/swkim-sm'><img src='https://avatars.githubusercontent.com/u/58676931?v=4' width='200px'/></a> |<a href='https://github.com/Yiujin'><img src='https://avatars.githubusercontent.com/u/43367868?v=4' width='200px'/></a>|<a href='https://github.com/binlee52'><img src='https://avatars.githubusercontent.com/u/24227863?v=4' width='200px'/></a>|<a href='https://github.com/sejongjeong'><img src='https://avatars.githubusercontent.com/u/37677446?v=4' width='200px'/></a>|<a href='https://github.com/JODONG2'><img src='https://avatars.githubusercontent.com/u/61579014?v=4' width='200px'/></a>|<a href='https://github.com/hojihun5516'><img src='https://avatars.githubusercontent.com/u/32387358?v=4' width='200px'/></a>|<a href='https://github.com/herjh0405'><img src='https://avatars.githubusercontent.com/u/54921730?v=4' width='200px'/></a>



<br></br>
## â™» ëŒ€íšŒ ê°œìš” <a name = 'Overview'></a>
ëŒ€ëŸ‰ ìƒì‚°, ëŒ€ëŸ‰ ì†Œë¹„ì˜ ì‹œëŒ€ì— ì‚´ë©° 'ì“°ë ˆê¸° ëŒ€ë€', 'ë§¤ë¦½ì§€ ë¶€ì¡±'ê³¼ ê°™ì€ ì—¬ëŸ¬ ì‚¬íšŒ ë¬¸ì œë¥¼ ë‚³ê³  ìˆë‹¤.  
ë¶„ë¦¬ìˆ˜ê±°ëŠ” ì´ëŸ¬í•œ í™˜ê²½ë¶€ë‹´ì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ë‹¤. í•´ë‹¹ ëŒ€íšŒëŠ” ì“°ë ˆê¸°ë¥¼ Segmentationí•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ ì •í™•í•œ ë¶„ë¦¬ìˆ˜ê±°ë¥¼ ë•ëŠ” ê²ƒì— ê¸°ì—¬í•œë‹¤. 

- Dataset ì„¤ëª…
  - 512 x 512 í¬ê¸°ì˜ train 2617ì¥ (80%) , public test 417ì¥ (10%) , private test 420ì¥(10%) 
  - ì´ 10ê°œì˜ class ì¡´ì¬ 
     - Background, General trash, Paper, Paper pack, Metal, Glass, Plastic, Styrofoam, Plastic bag, Battery, Clothing
  - coco formatìœ¼ë¡œ images , annotations ì •ë³´ ì¡´ì¬
    - images : id, height , width, filename
    - annotatins : id, segmentation mask , bbox, area, category_id , image_id
    
- í‰ê°€ë°©ë²• 
    - Semantic Segmentation : mIOU


<br></br>
## ğŸ“ ë¬¸ì œ ì •ì˜ ë° í•´ê²° ë°©ë²• <a name = 'Solution'></a>
- Template<br>
  pytorch template í˜•ì‹ì— ë§ê²Œ ì§ì ‘ êµ¬í˜„

- Model<br>
  FCN<br>
  UNet, UNet++<br>
  DeepLab, DeepLab++, DeepLab+++<br>
  HRNet, HRNet_OCR<br>

- Techniques<br>
  Data hard augmentation<br>
  Mixup, Cutmix<br>
  Stratified K-Fold<br>
  Pseudo Labeling<br>
  TTA<br>
  Ensemble<br>
  WandB<br>


<br></br>
## ğŸ’» CODE ì„¤ëª…<a name = 'Code'></a>

### Archive contents
```
segmentation
â”œâ”€â”€ input
â”‚   â””â”€â”€ data
â”œâ”€â”€ semantic-segmentation-level2-cv-02
â”‚   â”œâ”€â”€ base
â”‚   â”œâ”€â”€ data_loader
â”‚   â”œâ”€â”€ logger
â”‚   â”œâ”€â”€ loss
â”‚   â”œâ”€â”€ model
â”‚   â”œâ”€â”€ trainer
â”‚   â””â”€â”€ utils
â”œâ”€â”€ train.py
â”œâ”€â”€ train_kfold.py
â”œâ”€â”€ test.py
â”œâ”€â”€ test_TTA.py
â”œâ”€â”€ visulaize.py
â”œâ”€â”€ csv_ensemble.py
â””â”€â”€ create_resize_data.py
```

### Train
```
cd segmentation/semantic-segmentation-level2-cv-02
```
1. vanilla train   
```
python train.py [config path]
python train.py configs/config.json
```
2. k-fold train  
   config fileì— ì•„ë˜ì™€ ê°™ì€ ì¸ì ì¶”ê°€
   ```
       "kfold": {
        "flag": true,
        "cnt": 5,
        "train_fold": "../input/data/train_fold.json", 
        "valid_fold": "../input/data/val_fold.json"        
    },
   ```
```
python train_kfold.py [config path]
```
3. Pseudo Labeling Train & Inference   
512x512 ë¡œ inference í•œ csv file ì¤€ë¹„
```
python pseudo_labeling.py --test_csv [csv file path]
```
4. Expeiment with 256x256 image 
ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•œ 256x256 scale image ë¡œ ì‹¤í—˜
```
python create_resize_data.py
```
resized data ì‚¬ìš© ì‹œ config ì—ì„œ train, validation data loader ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •
```
"data_loader": {
"type": "ResizedBasicDataLoader",
"args": {
"dataset": {
"type": "ResizedBasicDataset",
"args": {
"data_dir": "../input/resized_data_256",
"mode": "train",
"transform": {"type": "BasicTransform", "args": {}}
}
```

### Inference
```
cd segmentation/semantic-segmentation-level2-cv-02
```
1. vanilla inference  
```
python test.py -c [config path] -r [pth path]
```
1. TTA inference
```
python test_TTA.py -c [config path] -r [pth path]
```

### Visualization Result
1. test ì´ë¯¸ì§€ ì‹œê°í™”<br>
   semantic-segmentation-level2-cv-02/visualize.py ì˜ submission_path ì— ì‹œê°í™”í•˜ê³ ì í•˜ëŠ” csvíŒŒì¼ ê²½ë¡œ ë„£ê³  Run Cell 
2. validation ì´ë¯¸ì§€ ì‹œê°í™”<br>
   wandb ì‚¬ìš©, utils/wandb.py ì˜ show_images_wandb í•¨ìˆ˜ë¡œ validation ì‹œ ì´ë¯¸ì§€ ì‹œê°í™”


### Ensemble
ensemble_method : Hard Voting
```
cd segmentation/semantic-segmentation-level2-cv-02
```
submission.csv ê²½ë¡œ ì¶”ê°€ í›„ 
```
python csv_ensemble.py
```

<br></br>
## ğŸ‘€ DEMO ê²°ê³¼<a name = 'Demo'></a>
Backbone : EfficientNet-b4  
Segmentation Head : UNet++  
| Original Image | Ground Truth | Predicted Image |
|:--------------:|:--------------:|:--------------:| 
|<a><img src = 'https://user-images.githubusercontent.com/43367868/140676444-6d618757-5eb8-4261-8477-1edbd0e74ae6.png' width ='200px' ></a>|<a><img src = 'https://user-images.githubusercontent.com/43367868/140676804-942640cf-df49-4ffe-b220-28f4c17f7b3e.png' width ='200px' ></a>|<a><img src = 'https://user-images.githubusercontent.com/43367868/140676912-acd44bf1-93fd-4c07-89b7-642d1c8e87f0.png' width ='200px' ></a>|
|<a><img src = 'https://user-images.githubusercontent.com/43367868/140677109-23493624-2fc1-45e0-bfe2-b4a5c2aa57f8.png' width ='200px' ></a>|<a><img src = 'https://user-images.githubusercontent.com/43367868/140677216-1043ab83-4286-492c-a12d-e8e390b929dd.png' width ='200px' ></a>|<a><img src = 'https://user-images.githubusercontent.com/43367868/140677164-6fd04b07-8461-4f0c-b2cc-a3fc73059668.png' width ='200px' ></a>|


data license : Naver Boostcamp AI Tech ëŒ€íšŒêµìœ¡ìš© ì¬í™œìš© ì“°ë ˆê¸° ë°ì´í„°ì…‹. CC BY 2.0