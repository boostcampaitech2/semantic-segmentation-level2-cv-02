{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1\n",
      "GPU 사용 가능 여부: True\n",
      "Tesla V100-SXM2-32GB\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.patches import Patch\n",
    "import webcolors\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "# GPU 사용 가능 여부에 따라 device 정보 저장\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  \n",
    "dataset_path  = '../input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train_all.json'\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = A.Compose([\n",
    "    A.Resize(width=1024, height=1024),\n",
    "]\n",
    ")\n",
    "\n",
    "\n",
    "category_names = ['Backgroud',\n",
    " 'General trash',\n",
    " 'Paper',\n",
    " 'Paper pack',\n",
    " 'Metal',\n",
    " 'Glass',\n",
    " 'Plastic',\n",
    " 'Styrofoam',\n",
    " 'Plastic bag',\n",
    " 'Battery',\n",
    " 'Clothing']\n",
    "\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.26s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "transform = transform1\n",
    "coco = COCO(anns_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(anns_file_path) as json_file:\n",
    "    origin_data_json = json.load(json_file)\n",
    "indexes = []\n",
    "for i in origin_data_json['images']:\n",
    "    indexes.append(i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj = {}\n",
    "\n",
    "for index in indexes:\n",
    "    image_id = coco.getImgIds(imgIds=index)\n",
    "    image_infos = coco.loadImgs(image_id)[0]\n",
    "\n",
    "    images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "    images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    images /= 255.0\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=image_infos['id'])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    cat_ids = coco.getCatIds()\n",
    "    cats = coco.loadCats(cat_ids)\n",
    "\n",
    "    masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "\n",
    "    anns = sorted(anns, key=lambda idx : len(idx['segmentation'][0]), reverse=False)\n",
    "    for i in range(len(anns)):\n",
    "        className = get_classname(anns[i]['category_id'], cats)\n",
    "        pixel_value = category_names.index(className)\n",
    "        masks[coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "    masks = masks.astype(np.int8)\n",
    "\n",
    "    # transform -> albumentations 라이브러리 활용\n",
    "    transformed = transform(image=images, mask=masks)\n",
    "    images = transformed[\"image\"]\n",
    "    masks = transformed[\"mask\"]\n",
    "\n",
    "    plt.imsave(f'./resized_data/image/{index}.jpg', images)\n",
    "    np.save(f'./resized_data/mask/{index}', masks)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36e052b391be8c28b05838ade06426769a29575d5fe21a7bc69c7dec0c04c06"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('segmentation': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
